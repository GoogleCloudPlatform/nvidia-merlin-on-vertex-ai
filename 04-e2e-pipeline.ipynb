{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7086876-72ed-4ac8-aeba-f05dbc641798",
   "metadata": {},
   "source": [
    "# End-to-end Recommender System with NVIDIA Merlin and Vertex AI.\n",
    "\n",
    "This notebook shows how to deploy and execute an end-to-end recommender system on Vertex Pipelines using NVIDIA Merlin.\n",
    "The notebook covers the following:\n",
    "\n",
    "1. Training pipeline overview.\n",
    "2. Set pipeline configurations.\n",
    "3. Build pipeline container images.\n",
    "4. Configure pipeline parameters.\n",
    "5. Compile KFP pipeline.\n",
    "6. Submit pipeline to Vertex AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13889502-7856-4d1f-bbf1-064a7978e225",
   "metadata": {},
   "source": [
    "## 1. Training Pipeline Overview\n",
    "\n",
    "The following diagram shows the end-to-end pipeline for preprocessing, training, and serving `NVIDIA Merlin` Recommender System using `Vertex AI`.\n",
    "The pipeline is defined in [src/training_pipelines.py](src/training_pipelines.py) module. \n",
    "\n",
    "The `training_bq` pipeline function reads the criteo data from `BigQuery` and perform the following steps:\n",
    "\n",
    "1. Preprocess the data using `NVTabular`, as described in the [01-dataset-preprocessing.ipynb](01-dataset-preprocessing.ipynb) notebook:\n",
    "    1. Export the `BigQuery` data to `Cloud Storage` as Parquet files.\n",
    "    2. Transform the data using an `NVTabular` workflow.\n",
    "    3. Write the transformed data as parquet files and the workflow object to `Cloud Storage`.\n",
    "2. Train a DeepFM model using `HugeCTR`. This step is submits a [Custom Training Job](https://cloud.google.com/vertex-ai/docs/training/create-custom-job) to `Vertex AI` training, as described in [02-model-training-hugectr.ipynb](02-model-training-hugectr.ipynb).\n",
    "3. Export the model as a `Triton` Ensemble to be served using `Triton` server. The ensemble consists of of the `NVTabular` preprocessing workflow and a `HugeCTR` model. \n",
    "4. The exported `Triton` ensemble model is uploaded to `Vertex AI` model resources.\n",
    "\n",
    "Once the model is uploaded to `Vertex AI`, a long with a reference to its serving `Triton` container, it can be deployed to `Vertex AI` Prediction, as described in [03-model-inference-hugectr.ipynb](03-model-inference-hugectr.ipynb). \n",
    "\n",
    "All the components of the pipelines are defined in the [src/pipelines/components.py](src/pipelines/components.py) module.\n",
    "\n",
    "<img src=\"images/merlin-vertex-e2e.png\" alt=\"Pipeline\" style=\"height: 50%; width:50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eee537-5fc7-480f-a011-ff56e8e623ab",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e9c16-0c12-4ada-a71e-125b08b2b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa917976-d352-4f1b-aeb2-798f7cbbef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'merlin-on-gcp' # Change to your project Id.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "BUCKET =  'merlin-on-gcp' # Change to your bucket.\n",
    "\n",
    "MODEL_NAME = 'deepfm'\n",
    "MODEL_VERSION = 'v01'\n",
    "MODEL_DISPLAY_NAME = f'criteo-hugectr-{MODEL_NAME}-{MODEL_VERSION}'\n",
    "WORKSPACE = f'gs://{BUCKET}/{MODEL_DISPLAY_NAME}'\n",
    "TRAINING_PIPELINE_NAME = f'merlin-training-pipeline'\n",
    "\n",
    "BQ_DATASET_NAME = 'criteo_pipeline' # Set to your BigQuery dataset including the Criteo dataset.\n",
    "BQ_LOCATION = 'us' # Set to your BigQuery dataset location.\n",
    "BQ_TRAIN_TABLE_NAME = 'train'\n",
    "BQ_VALID_TABLE_NAME = 'valid'\n",
    "\n",
    "NVT_IMAGE_NAME = 'nvt_preprocessing'\n",
    "NVT_IMAGE_URI = f'gcr.io/{PROJECT_ID}/{NVT_IMAGE_NAME}'\n",
    "NVT_DOCKERNAME = 'nvtabular'\n",
    "\n",
    "HUGECTR_IMAGE_NAME = 'hugectr_training'\n",
    "HUGECTR_IMAGE_URI = f'gcr.io/{PROJECT_ID}/{HUGECTR_IMAGE_NAME}'\n",
    "HUGECTR_DOCKERNAME = 'hugectr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9843d31-6716-40db-a88b-3eb2a051b2ea",
   "metadata": {},
   "source": [
    "## 2. Set Pipeline Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153b818-0d36-4101-a269-ada711ff76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PROJECT_ID'] = PROJECT_ID\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['WORKSPACE'] = WORKSPACE\n",
    "\n",
    "os.environ['BQ_DATASET_NAME'] = BQ_DATASET_NAME\n",
    "os.environ['BQ_LOCATION'] = BQ_LOCATION\n",
    "os.environ['BQ_TRAIN_TABLE_NAME'] = BQ_TRAIN_TABLE_NAME\n",
    "os.environ['BQ_VALID_TABLE_NAME'] = BQ_VALID_TABLE_NAME\n",
    "\n",
    "os.environ['TRAINING_PIPELINE_NAME'] = TRAINING_PIPELINE_NAME\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['MODEL_VERSION'] = MODEL_VERSION\n",
    "os.environ['MODEL_DISPLAY_NAME'] = MODEL_DISPLAY_NAME\n",
    "\n",
    "os.environ['NVT_IMAGE_URI'] = NVT_IMAGE_URI\n",
    "os.environ['HUGECTR_ITMAGE_URI'] = HUGECTR_IMAGE_URI\n",
    "\n",
    "os.environ['MEMORY_LIMIT'] = '120G'\n",
    "os.environ['CPU_LIMIT'] = '32'\n",
    "os.environ['GPU_LIMIT'] = '4'\n",
    "os.environ['GPU_TYPE'] = 'nvidia-tesla-t4'\n",
    "\n",
    "os.environ['MACHINE_TYPE'] = 'a2-highgpu-4g'\n",
    "os.environ['ACCELERATOR_TYPE'] = 'NVIDIA_TESLA_A100'\n",
    "os.environ['ACCELERATOR_NUM'] = '4'\n",
    "os.environ['NUM_WORKERS'] = '12'\n",
    "\n",
    "os.environ['NUM_SLOTS'] = '26'\n",
    "os.environ['MAX_NNZ'] = '2'\n",
    "os.environ['EMBEDDING_VECTOR_SIZE'] = '11'\n",
    "os.environ['MAX_BATCH_SIZE'] = '64'\n",
    "os.environ['MODEL_REPOSITORY_PATH'] = '/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7a468-618b-40e3-b0a5-546349801ff8",
   "metadata": {},
   "source": [
    "## 3. Build Pipeline Container Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5075a-f081-4589-8eae-dae8d62edd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = './src'\n",
    "! gcloud builds submit --config src/cloudbuild.yaml --substitutions _DOCKERNAME=$NVT_DOCKERNAME,_IMAGE_URI=$NVT_IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565ad2c-f145-481c-ae09-c9055ba043b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = './src'\n",
    "! gcloud builds submit --config src/cloudbuild.yaml --substitutions _DOCKERNAME=$HUGECTR_DOCKERNAME,_IMAGE_URI=$HUGECTR_IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee19e322-1ddf-4127-a31e-6992a582c797",
   "metadata": {},
   "source": [
    "## 4. Configure pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3fb0f-d012-4f31-81da-e10bf99d0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 0\n",
    "MAX_ITERATIONS = 50000\n",
    "EVAL_INTERVAL = 1000\n",
    "EVAL_BATCHES = 500\n",
    "EVAL_BATCHES_FINAL = 2500\n",
    "DISPLAY_INTERVAL = 200\n",
    "SNAPSHOT_INTERVAL = 0\n",
    "PER_GPU_BATCHSIZE = 2048\n",
    "LR = 0.001\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282810b-c760-4de7-a00e-8cf72c33f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values = {\n",
    "    'shuffle': json.dumps(None), # select PER_PARTITION, PER_WORKER, FULL, or None.\n",
    "    'per_gpu_batch_size': PER_GPU_BATCHSIZE,\n",
    "    'max_iter': MAX_ITERATIONS,\n",
    "    'max_eval_batches': EVAL_BATCHES ,\n",
    "    'eval_batches': EVAL_BATCHES_FINAL ,\n",
    "    'dropout_rate': DROPOUT_RATE,\n",
    "    'lr': LR ,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'eval_interval': EVAL_INTERVAL,\n",
    "    'snapshot': SNAPSHOT_INTERVAL,\n",
    "    'display_interval': DISPLAY_INTERVAL\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93628fa4-41e0-4ac2-9162-8c971383fb74",
   "metadata": {},
   "source": [
    "## 5. Compile KFP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc54b32-c48b-4d66-882f-6bd0e29678e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.training_pipelines import training_bq\n",
    "\n",
    "compiled_pipeline_path = 'merlin_training_bq.json'\n",
    "compiler.Compiler().compile(\n",
    "       pipeline_func=training_bq,\n",
    "       package_path=compiled_pipeline_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4e255-f4a6-474c-aed4-d225cefdfbd5",
   "metadata": {},
   "source": [
    "## 6. Submit pipeline to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ecf7a1-9b79-4386-baa3-e5ff74347ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f'merlin_training_bq_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "\n",
    "pipeline_job = vertex_ai.PipelineJob(\n",
    "    display_name=job_name,\n",
    "    template_path=compiled_pipeline_path,\n",
    "    enable_caching=False,\n",
    "    parameter_values=parameter_values,\n",
    ")\n",
    "\n",
    "pipeline_job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3534ea-3cce-4a73-8b8e-594e21d6403a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "common-cpu.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m86"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
