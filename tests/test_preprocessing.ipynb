{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Global variables and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'renatoleite-mldemos' # Change to your project Id.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "BUCKET =  'renatoleite-nvtabular' # Change to your bucket.\n",
    "\n",
    "IMAGE_NAME = 'nvt_preprocessing'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "DOCKERNAME = 'nvtabular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = 'None'\n",
    "train_split = 'train'\n",
    "valid_split = 'valid'\n",
    "n_workers = 1\n",
    "recursive = False\n",
    "\n",
    "local_dev_folder = '/home/renatoleite/nvidia-merlin-on-vertex-ai/tests'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build docker image with Cloud Build\n",
    "! gcloud builds submit --config ../src/cloudbuild.yaml --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from renatoleite-mldemos/nvt_preprocessing\n",
      "Digest: sha256:707c4d589b9f8b6af2948924a07d33fe891d75bfb073b528ca63b488e9f26ab4\n",
      "Status: Image is up to date for gcr.io/renatoleite-mldemos/nvt_preprocessing:latest\n",
      "gcr.io/renatoleite-mldemos/nvt_preprocessing:latest\n"
     ]
    }
   ],
   "source": [
    "# Pull image locally to test\n",
    "! docker pull $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create local directory to read/write files\n",
    "\n",
    "This folder will work like a GCSfuse mount point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gcs/renatoleite-nvtabular\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = f'/gcs/{BUCKET}'\n",
    "print(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"/gcs/renatoleite-nvtabular\" already exists\n"
     ]
    }
   ],
   "source": [
    "# Create BASE_DIR if not exists\n",
    "if not os.path.exists(BASE_DIR):\n",
    "    os.makedirs(BASE_DIR)\n",
    "    print(f'Directory \\\"{BASE_DIR}\\\" created')\n",
    "else:\n",
    "    print(f'Directory \\\"{BASE_DIR}\\\" already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert CSV to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training / Validation\n",
    "train_paths = 'gs://workshop-datasets/criteo/day_1' # Training CSV file to be preprocessed.\n",
    "valid_paths = 'gs://workshop-datasets/criteo/day_0' # Validation CSV file to be preprocessed.\n",
    "num_output_files_train = 1\n",
    "num_output_files_valid = 1\n",
    "convert_path = os.path.join(BASE_DIR, 'convert-csv-parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Training files from CSV to Parquet\n",
    "! docker run -it --rm --gpus all \\\n",
    "-v $local_dev_folder:/tests \\\n",
    "-v $BASE_DIR:$BASE_DIR \\\n",
    "$IMAGE_URI \\\n",
    "python /tests/test_preprocessing.py \\\n",
    "--method-to-call convert_csv_to_parquet_op \\\n",
    "--output-path $convert_path \\\n",
    "--data-paths $train_paths \\\n",
    "--split $train_split \\\n",
    "--num-output-files $num_output_files_train \\\n",
    "--n-workers $n_workers \\\n",
    "--recursive $recursive \\\n",
    "--device-limit-frac 0.8 \\\n",
    "--device-pool-frac 0.9 \\\n",
    "--part-mem-frac 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Validation files from CSV to Parquet\n",
    "! docker run -it --rm --gpus all \\\n",
    "-v $local_dev_folder:/tests \\\n",
    "-v $BASE_DIR:$BASE_DIR \\\n",
    "$IMAGE_URI \\\n",
    "python /tests/test_preprocessing.py \\\n",
    "--method-to-call convert_csv_to_parquet_op \\\n",
    "--output-path $convert_path \\\n",
    "--data-paths $valid_paths \\\n",
    "--split $valid_split \\\n",
    "--num-output-files $num_output_files_valid \\\n",
    "--n-workers $n_workers \\\n",
    "--recursive $recursive \\\n",
    "--device-limit-frac 0.8 \\\n",
    "--device-pool-frac 0.9 \\\n",
    "--part-mem-frac 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy converted files back to GCS\n",
    "! gsutil -m cp -r $convert_path gs://renatoleite-nvtabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (analyse) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = f'gs://{BUCKET}/convert-csv-parquet'\n",
    "workflow_path = f'/gcs/{BUCKET}/workflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run -it --rm --gpus all \\\n",
    "-v $local_dev_folder:/tests \\\n",
    "-v $BASE_DIR:$BASE_DIR \\\n",
    "$IMAGE_URI \\\n",
    "python /tests/test_preprocessing.py \\\n",
    "--method-to-call analyze_dataset_op \\\n",
    "--output-path $parquet_path \\\n",
    "--workflow-path $workflow_path \\\n",
    "--split $train_split \\\n",
    "--n-workers $n_workers \\\n",
    "--recursive $recursive \\\n",
    "--device-limit-frac 0.8 \\\n",
    "--device-pool-frac 0.9 \\\n",
    "--part-mem-frac 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil -m cp -r $workflow_path gs://renatoleite-nvtabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = f'gs://{BUCKET}/convert-csv-parquet'\n",
    "workflow_path = f'/gcs/{BUCKET}/workflow'\n",
    "transformed_dataset = f'/gcs/{BUCKET}/transformed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run -it --rm --gpus all \\\n",
    "-v $local_dev_folder:/tests \\\n",
    "-v $BASE_DIR:$BASE_DIR \\\n",
    "$IMAGE_URI \\\n",
    "python /tests/test_preprocessing.py \\\n",
    "--method-to-call transform_dataset_op \\\n",
    "--output-path $parquet_path \\\n",
    "--workflow-path $workflow_path \\\n",
    "--transformed-dataset $transformed_dataset \\\n",
    "--split $train_split \\\n",
    "--n-workers $n_workers \\\n",
    "--recursive $recursive \\\n",
    "--device-limit-frac 0.8 \\\n",
    "--device-pool-frac 0.9 \\\n",
    "--part-mem-frac 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil -m cp -r $transformed_dataset gs://renatoleite-nvtabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Parquet files from BigQuery to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'gs://{BUCKET}/bq_export_parquet'\n",
    "bq_project = PROJECT_ID\n",
    "bq_location = 'us'\n",
    "bq_dataset_name = 'criteo_small'\n",
    "bq_table_name = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-11-21 10:14:53 - Args: Namespace(bq_dataset_name='criteo_small', bq_location='us', bq_project='renatoleite-mldemos', bq_table_name='train', data_paths='', device_limit_frac=0.8, device_pool_frac=0.9, method_to_call='export_parquet_from_bq_op', n_workers=1, num_output_files=1, output_path='gs://renatoleite-nvtabular/bq_export_parquet', part_mem_frac=0.125, recursive=False, sep='\\t', shuffle='None', split='train', transformed_dataset='', workflow_path='')\n",
      "18-11-21 10:14:53 - Starting job.\n",
      "18-11-21 10:14:56 - Extracting train table to gs://renatoleite-nvtabular/bq_export_parquet/train path.\n",
      "18-11-21 10:14:58 - Finished exporting to GCS.\n"
     ]
    }
   ],
   "source": [
    "! docker run -it --rm --gpus all \\\n",
    "-v $local_dev_folder:/tests \\\n",
    "-v $BASE_DIR:$BASE_DIR \\\n",
    "$IMAGE_URI \\\n",
    "python /tests/test_preprocessing.py \\\n",
    "--method-to-call export_parquet_from_bq_op \\\n",
    "--output-path $output_path \\\n",
    "--bq-project $bq_project \\\n",
    "--bq-location $bq_location \\\n",
    "--bq-dataset-name $bq_dataset_name \\\n",
    "--bq-table-name $bq_table_name \\\n",
    "--split $train_split"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
