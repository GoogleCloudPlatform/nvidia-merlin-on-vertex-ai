{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files from Criteo Dataset\n",
    "\n",
    "For this test, only one file from Criteo dataset was downloaded (1 day).  \n",
    "You can ajust the variable \"NUMBER_OF_DAYS\" to \n",
    "These tests are run locally on a conda environment and on a containers. To install the latest version of the NVTabular software, please refer to https://github.com/NVIDIA-Merlin/NVTabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 1 file from Criteo website\n",
    "import os\n",
    "\n",
    "from nvtabular.utils import download_file\n",
    "\n",
    "BASE_DIR = '/home/renatoleite/data'\n",
    "input_path = os.path.join(BASE_DIR, \"crit_orig\")\n",
    "NUMBER_DAYS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BASE_DIR if not exists\n",
    "if not os.path.exists(BASE_DIR):\n",
    "    os.makedirs(BASE_DIR)\n",
    "    print(f'Directory \\\"{BASE_DIR}\\\" created')\n",
    "else:\n",
    "    print(f'Directory \\\"{BASE_DIR}\\\" already exists')\n",
    "\n",
    "# Create input dir if not exists\n",
    "if not os.path.exists(input_path):\n",
    "    os.makedirs(input_path)\n",
    "    print(f'Directory \\\"{input_path}\\\" created')\n",
    "else:\n",
    "    print(f'Directory \\\"{input_path}\\\" already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over days\n",
    "for i in range(0, NUMBER_DAYS):\n",
    "    file = os.path.join(input_path, \"day_\" + str(i) + \".gz\")\n",
    "    # Download file, if there is no .gz, .csv or .parquet file\n",
    "    if not (\n",
    "        os.path.exists(file)\n",
    "        or os.path.exists(\n",
    "            file.replace(\".gz\", \".parquet\").replace(\"crit_orig\", \"converted/criteo/\")\n",
    "        )\n",
    "        or os.path.exists(file.replace(\".gz\", \"\"))\n",
    "    ):\n",
    "        download_file(\n",
    "            \"http://azuremlsampleexperiments.blob.core.windows.net/criteo/day_\"\n",
    "            + str(i)\n",
    "            + \".gz\",\n",
    "            file\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'gs://renatoleite-nvtabular/crit_orig_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil -m cp $input_path/* $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "Analysis of one Criteo file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file header\n",
    "HEADER = [\"label\"]\n",
    "for i in range(1, 14):\n",
    "  HEADER.append(f\"I{i}\")\n",
    "for i in range(1, 27):\n",
    "  HEADER.append(f\"C{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500000\n",
    "\n",
    "day1_dataset = pd.read_csv(\n",
    "    f\"{BUCKET_NAME}/day_0.gz\",\n",
    "    sep=\"\\t\",\n",
    "    names=HEADER,\n",
    "    nrows=sample_size    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_dataset.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file to BigQuery Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'renatoleite-mldemos'\n",
    "REGION = 'us-central1'\n",
    "DATASET_GCS_LOCATION = 'gs://renatoleite-nvtabular/crit_orig_csv'\n",
    "BQ_DATASET_NAME = 'criteo'\n",
    "BQ_TRAIN_TABLE_NAME = 'train'\n",
    "BQ_VALID_TABLE_NAME = 'valid'\n",
    "NUM_FILES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq --location=US mk -d \\\n",
    "$PROJECT:$BQ_DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SCHEMA to load the data\n",
    "schema = []\n",
    "for column in HEADER:\n",
    "    if \"C\" in column:\n",
    "        schema.append(f\"{column}:STRING\")\n",
    "    else:\n",
    "        schema.append(f\"{column}:INTEGER\")\n",
    "schema = ','.join(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for v in range(NUM_FILES):\n",
    "    train_files.append(f'\"{DATASET_GCS_LOCATION}/day_{v}\"')\n",
    "\n",
    "train_files = ','.join(train_files)\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq load \\\n",
    "    --source_format=CSV \\\n",
    "    --field_delimiter=tab \\\n",
    "    --autodetect \\\n",
    "    --replace \\\n",
    "    {BQ_DATASET_NAME}.{BQ_TRAIN_TABLE_NAME} \\\n",
    "    {train_files} \\\n",
    "    {schema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq load \\\n",
    "    --source_format=CSV \\\n",
    "    --field_delimiter=tab \\\n",
    "    --autodetect \\\n",
    "    --replace \\\n",
    "    {BQ_DATASET_NAME}.{BQ_VALID_TABLE_NAME} \\\n",
    "    {DATASET_GCS_LOCATION}/day_0 \\\n",
    "    {schema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
